\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{tabularx} % extra features for tabular environment
\usepackage{amsmath}  % improve math presentation
\usepackage{graphicx} % takes care of graphic including machinery
\usepackage{xspace}
\usepackage{tikz}
\usepackage{enumitem}
\usetikzlibrary{babel}
\usepackage[american]{circuitikz}
\usetikzlibrary{calc}
\usepackage{float}
\usepackage{siunitx}
\usepackage{pgfplots}
\usepackage{amsfonts} 
\usetikzlibrary{intersections}
\usepgfplotslibrary{fillbetween}
\usepackage[skins,theorems]{tcolorbox}
\tcbset{highlight math style={enhanced,
  colframe=red,colback=white,arc=0pt,boxrule=1pt}}
\pgfplotsset{width=10cm,compat=1.9}
\usepackage[margin=1in,letterpaper]{geometry} % decreases margins
\usepackage{cite} % takes care of citations
\usepackage[final]{hyperref} % adds hyper links inside the generated PDF file
\hypersetup{
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=blue,        % color of internal links
citecolor=blue,        % color of links to bibliography
filecolor=magenta,     % color of file links
urlcolor=blue        
}

\begin{document}

\title{\textbf{CONVEX OPTIMISATION}\\{\textbf{ASSIGNMENT }}}
\author{\textbf{TADIPATRI UDAY KIRAN REDDY}\\\textbf{EE19BTECH11038}}
\maketitle

\section*{\hfil Question 1}
\subsection*{(a)}
Problem (2), (3) and (4) are always convex but Problem (3) are not always convex because hessian of objective for problem (1) is,
\begin{equation*}
	\mathbf{H} = \mathbf{A}^T\mathbf{A} + \alpha\mathbf{I}	
\end{equation*}
Positive definitness of hessian is dependent on the value $\alpha$.
\subsection*{(b)}
\begin{gather*}
	\Delta Objective = \left(\partial \frac{\overline{x}^T(\mathbf{A}^T\mathbf{A}+\alpha \mathbf{I})\overline{x} - \overline{y}^T\mathbf{A}\overline{x} + \overline{y}^T\overline{y}}{\partial \overline{x}}\right)^T\\
	\implies \Delta Objective = 2(\mathbf{A}^T\mathbf{A}+\alpha \mathbf{I})\overline{x} - \overline{y}^T\mathbf{A}
\end{gather*}
\subsection*{(c)}
\begin{gather*}
	\Delta Objective = 0\\
	\implies \overline{x}^* = 0.5(\mathbf{A}^T\mathbf{A}+\alpha \mathbf{I})^{-1}\mathbf{A}^T\overline{y}
\end{gather*}
\subsection*{(d)}
\subsection*{(e)}

\section*{\hfil Question 2}
\section*{\hfil Question 3}
\subsection*{(a)}
To prove that the objective function is quasi-convex we ned to show that all $\alpha$ level subsets are convex.
	\begin{gather*}
		\frac{\overline{\mu}^T\overline{x}}{||\mathbf{V}\overline{x}||_2} \le \alpha \implies \frac{\overline{x}^T\overline{\mu}\overline{\mu}^T\overline{x}}{\overline{x}^T\mathbf{V}^T\mathbf{V}\overline{x}} \le \alpha ^2\\
		\implies \overline{x}^T\left(\alpha ^2\mathbf{V}^T\mathbf{V} + \overline{\mu}\overline{\mu}^T\right)\overline{x} \ge 0
	\end{gather*}
	Given that $\mathbf{V}$ is symmentric which means $\mathbf{V}^T\mathbf{V}$ and  outer product of matrices is positive defnite matrix. Therefore sum of positive semidefnite matrices is positive semidefnite. Thus the given objective function is quasi-convex.
\subsection*{(b)}
\begin{gather*}
	\overline{z} = \frac{\overline{x}}{\overline{\mu}^T\overline{x}}\\\implies
	\frac{\overline{z}}{\overline{1}^T\overline{z}} = \frac{\frac{\overline{x}}{\overline{\mu}^T\overline{x}}}{\frac{\overline{1}^T\overline{x}}{\overline{\mu}^T\overline{x}}}\\
	\implies \tcbhighmath[drop fuzzy shadow]{\overline{x} = \frac{\overline{z}}{\overline{1}^T\overline{z}}}\\
	\frac{\overline{\mu}^T\overline{x}}{||\mathbf{V}\overline{x}||_2} = \frac{\overline{\mu}^T\frac{\overline{z}}{\overline{1}^T\overline{z}}}{||\mathbf{V}\frac{\overline{z}}{\overline{1}^T\overline{z}}||_2} = \frac{sgn\left(\overline{1}^T\overline{z}\right)}{||\mathbf{V}\overline{z}||_2}
\end{gather*}
Given $\overline{\mu}^T\overline{x} \ge 0$ and $\overline{1}^T\overline{x} = 1$ which means $\overline{1}^T\overline{z} = \frac{1}{\overline{\mu}^T\overline{x}} > 0$.
\begin{gather*}
	\implies \tcbhighmath[drop fuzzy shadow]{\frac{\overline{\mu}^T\overline{x}}{||\mathbf{V}\overline{x}||_2} = \frac{1}{||\mathbf{V}\overline{z}||_2}}\\
	||\overline{x}||_1 \le L \implies ||\frac{\overline{z}}{\overline{1}^T\overline{z}}||_1 \le L\\
	{||\overline{z}||_1} \le L{\overline{1}^T\overline{z}}
\end{gather*}
Now transformed problem is,
\begin{gather*}
	\begin{aligned}
		\min \quad & ||\mathbf{V}\overline{z}||_2\\
		\textrm{s.t} \quad & {||\overline{z}||_1} \le L{\overline{1}^T\overline{z}}
	\end{aligned}
\end{gather*}
The above transformed problem has both convex objective and constraints thus it is convex optimisation problem.
\section*{\hfil Question 4}
\subsection*{(a)}
\textit{Lemma:} $(\mathbf{A} + \mathbf{B})^{-1} = \mathbf{A}^{-1} - (I + \mathbf{A}^{-1}\mathbf{B})^{-1}\mathbf{A}^{-1}\mathbf{B}\mathbf{A}^{-1}$.\\
If $g(x)$ is convex then so is $\overline{a}^Tg(x)\overline{a}$ because the map linear with respective to $g(x)$.\\
Now it is sufficient to prove the convexity of $\mathbf{X}^{-1}$. We do this by contradiction assume that the function is not convex which means,
\begin{gather*}
	(\alpha \mathbf{A})^{-1} + ((1-\alpha)\mathbf{B})^{-1} < \left(\alpha \mathbf{A} + (1-\alpha)\mathbf{B}\right)^{-1}\\
	\frac{1}{\alpha} \mathbf{A}^{-1} + \frac{1}{1-\alpha}\mathbf{B}^{-1} < \alpha \mathbf{A}^{-1} - \frac{1-\alpha}{\alpha ^2}(I + \frac{1-\alpha}{\alpha}\mathbf{A}^{-1}\mathbf{B})^{-1}\mathbf{A}^{-1}\mathbf{BA}^{-1}
\end{gather*}
Since the matrices are positve semi-definite multiplication on inequality will not change the sign.
\begin{gather*}
	\frac{1}{1-\alpha}\mathbf{B}^{-1} <  - \frac{1-\alpha}{\alpha ^2}(I + \frac{1-\alpha}{\alpha}\mathbf{A}^{-1}\mathbf{B})^{-1}\mathbf{A}^{-1}\mathbf{BA}^{-1}\\
	\implies \left(\frac{1-\alpha}{\alpha}\mathbf{A}^{-1}\mathbf{B}\right)^2 + \left(\frac{1-\alpha}{\alpha}\mathbf{A}^{-1}\mathbf{B}\right) + I < 0
\end{gather*}
Since $\mathbf{A} \ge 0$ and $\mathbf{B} \ge 0$ so is $\mathbf{A}^{-1}\mathbf{B} \ge 0 \implies \frac{1-\alpha}{\alpha}\mathbf{A}^{-1}\mathbf{B} \ge 0$.Therfore the above obtained sum is just sum of positive semi definite matrices which is positive semi definite but we got negative definite which is a contradiction. Thus our assumption is wrong. Therfore $\mathbf{X}^{-1}$ is convex and so is $\overline{a}^T\mathbf{X}^{-1}\overline{a}$.
\subsection*{(b)}

\subsection*{(c)}

\subsection*{(d)}

\subsection*{(e)}

\section*{\hfil Question 5}
\section*{\hfil Question 6}
Primal is
\begin{gather*}
	\overline{x} = \begin{bmatrix}
	x_1 \\
	x_2 
	\end{bmatrix}\\
	\begin{aligned}
		\min \quad & \overline{x}^T\begin{bmatrix}
		1 & -0.5\\
		-0.5 & 2
		\end{bmatrix}\overline{x} + \begin{bmatrix}
		-1 & 0
		\end{bmatrix}\overline{x}\\
		\textrm{s.t} \quad & \begin{bmatrix}
		1 & -2\\
		1 & 4\\
		5 & -76
		\end{bmatrix}\overline{x} \le \begin{bmatrix}
		u_1\\
		u_2\\
		1
		\end{bmatrix}
	\end{aligned}
\end{gather*}
Dual is 
\subsection*{(a)}
The above objective is in quadratic form and eigen decomposition of the hessian is
\begin{gather*}
	\begin{bmatrix}
		1 & -0.5\\
		-0.5 & 2
	\end{bmatrix} = \begin{bmatrix}
		-0.92387953 & 0.38268343\\
		-0.38268343 & -0.92387953
		\end{bmatrix}\begin{bmatrix}
		0.79289322 & 0\\
		0 & 2.20710678
		\end{bmatrix}\begin{bmatrix}
		-0.92387953 & -0.38268343\\
		0.38268343 & -0.92387953
		\end{bmatrix}
\end{gather*}
Here both eigen values are positive, which implies that hessian is positive semidefnite. With linear constraints, The problem is convex and is a QP.
\subsection*{(b)}
After solving the problem with \textit{CVXPY} we get,
\begin{gather*}
	x_1^* = -3;
	x_2^* = 0\\
	\lambda _{1}^* = 5.167; \lambda _{2}^* = 1.834;\lambda _{3}^* = 0
\end{gather*}
\subsection*{(c)}
\textbf{KKT Conditions}\\
\begin{enumerate}
	\item $f_i(x^*) \le 0$, Satisfied.\\
	\begin{gather*}
	\begin{bmatrix}
		1 & -2\\
		1 & 4\\
		5 & -76
		\end{bmatrix}\begin{bmatrix}
		-3\\
		0
		\end{bmatrix} \le \begin{bmatrix}
		-2\\
		-3\\
		1
	\end{bmatrix}
	\implies \begin{bmatrix}
		-3\\
		-3\\
		-15
	\end{bmatrix} \le \begin{bmatrix}
		-2\\
		-3\\
		1
	\end{bmatrix}
	\end{gather*}
	\item $\lambda _i^* \ge 0$, Satisfied.
	\item $\lambda _i^*f_i(x^*) = 0$, Satisfied.
	\begin{gather*}
		\begin{bmatrix}
		5.167 & 1.834 & 0
		\end{bmatrix}\left(\begin{bmatrix}
		-3\\
		-3\\
		-15
	\end{bmatrix} - \begin{bmatrix}
		-2\\
		-3\\
		1
	\end{bmatrix}\right) = 0
	\end{gather*}
\end{enumerate}
\subsection*{(d)}
\begin{figure}[H]
	\includegraphics[scale=1]{./figs/p.png}
\end{figure}
\subsection*{(e)}
From above graph it seems like $p^*(u_1, u_2)$ is a convex function.
\subsection*{(f)}
Numerically derivated at the given point is 0.
\begin{figure}[H]
	\includegraphics[scale=1]{./figs/p_dash.png}
\end{figure}
\end{document}